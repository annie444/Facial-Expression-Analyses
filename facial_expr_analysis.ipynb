{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install ffmpeg-python h5py matplotlib numpy pandas scipy scikit-learn ipympl plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ffmpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpprint\u001b[39;00m \u001b[39mimport\u001b[39;00m pprint\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m SimpleNamespace\n\u001b[0;32m---> 11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mffmpeg\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mh5py\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ffmpeg'"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import platform\n",
    "import re\n",
    "from datetime import datetime as dt\n",
    "from datetime import tzinfo as tz\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from types import SimpleNamespace\n",
    "import ffmpeg\n",
    "import h5py\n",
    "import numpy as np\n",
    "import numpy.lib.recfunctions as rf\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn as skl\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import signal\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import savgol_filter\n",
    "from mpl_toolkits import mplot3d\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import cv2\n",
    "from math import nan, isnan\n",
    "from scipy.stats import zscore\n",
    "import statistics\n",
    "import time\n",
    "import hdfdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing(Y, kind=\"linear\"):\n",
    "    \"\"\"Fills missing values independently along each dimension after the first.\"\"\"\n",
    "\n",
    "    # Store initial shape.\n",
    "    initial_shape = Y.shape\n",
    "\n",
    "    # Flatten after first dim.\n",
    "    Y = Y.reshape((initial_shape[0], -1))\n",
    "\n",
    "    # Interpolate along each slice.\n",
    "    for i in range(Y.shape[-1]):\n",
    "        y = Y[:, i]\n",
    "\n",
    "        # Build interpolant.\n",
    "        x = np.flatnonzero(~np.isnan(y))\n",
    "        f = interp1d(x, y[x], kind=kind, fill_value=np.nan, bounds_error=False)\n",
    "\n",
    "        # Fill missing\n",
    "        xq = np.flatnonzero(np.isnan(y))\n",
    "        y[xq] = f(xq)\n",
    "\n",
    "        # Fill leading or trailing NaNs with the nearest non-NaN values\n",
    "        mask = np.isnan(y)\n",
    "        y[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), y[~mask])\n",
    "\n",
    "        # Save slice\n",
    "        Y[:, i] = y\n",
    "\n",
    "    # Restore to initial shape.\n",
    "    Y = Y.reshape(initial_shape)\n",
    "\n",
    "    return Y\n",
    "\n",
    "\n",
    "def smooth_diff(node_loc, win=25, poly=3):\n",
    "    \"\"\"\n",
    "    node_loc is a [frames, 2] array\n",
    "\n",
    "    win defines the window to smooth over\n",
    "\n",
    "    poly defines the order of the polynomial\n",
    "    to fit with\n",
    "\n",
    "    \"\"\"\n",
    "    node_loc_vel = np.zeros_like(node_loc)\n",
    "\n",
    "    for c in range(node_loc.shape[-1]):\n",
    "        node_loc_vel[:, c] = savgol_filter(node_loc[:, c], win, poly, deriv=1)\n",
    "\n",
    "    node_vel = np.linalg.norm(node_loc_vel, axis=1)\n",
    "\n",
    "    return node_vel\n",
    "\n",
    "\n",
    "def into_trial_format(var, trial_start_idx, trial_end_idx):\n",
    "    var_trials = []\n",
    "    for start, end in zip(trial_start_idx, trial_end_idx):\n",
    "        var_trials.append(var[start:end])\n",
    "    return var_trials\n",
    "\n",
    "# create gaussian kernel for smoothing\n",
    "def gaussian_kernel(window_size, sigma=1):\n",
    "    x_vals = np.arange(window_size)\n",
    "    to_ret = np.exp(-((x_vals - window_size//2) * 2) / (2 * sigma * 2))\n",
    "    to_ret[:window_size//2] = 0\n",
    "    return to_ret\n",
    "\n",
    "def reduce_led(iterable: list) -> list[float]:\n",
    "    list: list[float] = []\n",
    "    j: int = 0\n",
    "    list.append(iterable[j])\n",
    "    for i in range(0, len(iterable)):\n",
    "        if iterable[j] < (iterable[i] - 5000):\n",
    "            j = i\n",
    "            list.append(iterable[j])\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the paths and the mice\n",
    "\n",
    "if platform.system() == 'Darwin':\n",
    "    data_path = f\"/Volumes/specialk_cs/2p/raw/\"\n",
    "else:   \n",
    "    data_path = f\"/nadata/snlkt/specialk_cs/2p/raw/\"\n",
    "\n",
    "mice = [\"CSC009\", \"CSC013\", \"CSE008\", \"CSE021\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSC009 -- starting\n",
      "\tWeek: 0 : Date: 20211106 -- done\n",
      "\tWeek: 1 : Date: 20211111 -- done\n",
      "\tWeek: 2 : Date: 20211118 -- done\n",
      "\tWeek: 3 : Date: 20211125 -- done\n",
      "\tWeek: 4 : Date: 20211202 -- done\n",
      "\tWeek: 5 : Date: 20211209 -- done\n",
      "\tWeek: 6 : Date: 20211214 -- done\n",
      "CSC009 -- complete\n",
      "CSC013 -- starting\n",
      "\tWeek: 0 : Date: 20211104 -- done\n",
      "\tWeek: 1 : Date: 20211111 -- done\n",
      "\tWeek: 2 : Date: 20211118 -- done\n",
      "\tWeek: 3 : Date: 20211125 -- done\n",
      "\tWeek: 4 : Date: 20211202 -- done\n",
      "\tWeek: 5 : Date: 20211209 -- done\n",
      "\tWeek: 6 : Date: 20211214 -- done\n",
      "CSC013 -- complete\n",
      "CSE008 -- starting\n",
      "\tWeek: 0 : Date: 20211105 -- done\n",
      "\tWeek: 1 : Date: 20211112 -- done\n",
      "\tWeek: 2 : Date: 20211119 -- done\n",
      "\tWeek: 3 : Date: 20211126 -- done\n",
      "\tWeek: 4 : Date: 20211203 -- done\n",
      "\tWeek: 5 : Date: 20211210 -- done\n",
      "\tWeek: 6 : Date: 20211215 -- done\n",
      "CSE008 -- complete\n",
      "CSE021 -- starting\n",
      "\tWeek: 0 : Date: 20211106 -- done\n",
      "\tWeek: 1 : Date: 20211113 -- done\n",
      "\tWeek: 2 : Date: 20211120 -- done\n",
      "\tWeek: 3 : Date: 20211127 -- done\n",
      "\tWeek: 4 : Date: 20211204 -- done\n",
      "\tWeek: 5 : Date: 20211211 -- done\n",
      "\tWeek: 6 : Date: 20211216 -- done\n",
      "CSE021 -- complete\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# create a list of dictionaries of lists to sort by \n",
    "# mouse (list) then variable name (dictionary) and variable values (list)\n",
    "\n",
    "exprs = [{} for _ in range(len(mice))]\n",
    "for m, mouse in enumerate(mice):\n",
    "    print(mouse, \"-- starting\")\n",
    "    \n",
    "    # get each week folder from mouse base directory\n",
    "    _, weeks, _ = next(os.walk(data_path + mouse), ([], [], []))\n",
    "\n",
    "    # complete the path for each week in order of completion\n",
    "    # (i.e. week 0 is the first week, week 1 the second)\n",
    "    weeks.sort()\n",
    "    n_weeks = len(weeks)\n",
    "    base_path = data_path + mouse\n",
    "    week_filter = np.zeros(n_weeks, dtype=bool)\n",
    "    data = [[] for _ in range(n_weeks)]\n",
    "\n",
    "    # Create behavior arrays for each varriable \n",
    "    # with the length as the number of weeks\n",
    "    airpuff_on = [[] for _ in range(n_weeks)]\n",
    "    airpuff_off = [[] for _ in range(n_weeks)]\n",
    "\n",
    "    licks_on = [[] for _ in range(n_weeks)]\n",
    "    licks_off = [[] for _ in range(n_weeks)]\n",
    "\n",
    "    sucrose_on = [[] for _ in range(n_weeks)]\n",
    "    sucrose_off = [[] for _ in range(n_weeks)]\n",
    "\n",
    "    LED_on = [[] for _ in range(n_weeks)]\n",
    "    LED_off = [[] for _ in range(n_weeks)]\n",
    "\n",
    "    speaker_on = [[] for _ in range(n_weeks)]\n",
    "    speaker_off = [[] for _ in range(n_weeks)]\n",
    "\n",
    "    video_metadata = [[] for _ in range(n_weeks)]\n",
    "    beh_metadata = [[] for _ in range(n_weeks)]\n",
    "    trialArray = [[] for _ in range(n_weeks)]\n",
    "    ITIArray = [[] for _ in range(n_weeks)]\n",
    "\n",
    "    \n",
    "    # enumerate each week folder\n",
    "    for w, week in enumerate(weeks):\n",
    "        os.chdir(f\"{base_path}/{weeks[w]}/\")\n",
    "        \n",
    "        # get data from the csv files\n",
    "        for csv in glob.glob(\"*.csv\"):\n",
    "            data[w] = pd.read_csv(f\"{base_path}/{weeks[w]}/{csv}\")\n",
    "            \n",
    "        # get data from the json files\n",
    "        for js in glob.glob(\"*.json\"):\n",
    "            with open(f\"{base_path}/{weeks[w]}/{js}\", \"r\") as js_file:\n",
    "                js_file = json.load(js_file)\n",
    "                beh_metadata[w] = js_file.get(\"beh_metadata\")\n",
    "                trialArray[w] = js_file.get(\"beh_metadata\")[\"trialArray\"]\n",
    "                ITIArray[w] = js_file.get(\"beh_metadata\")[\"ITIArray\"]\n",
    "\n",
    "        # get the video metadata\n",
    "        for video in glob.glob(\"*.mp4\"):\n",
    "            if len(glob.glob(\"*.mp4\")) > 1:\n",
    "                continue\n",
    "            else:\n",
    "                video_metadata[w] = ffmpeg.probe(f\"{base_path}/{weeks[w]}/{video}\")[\n",
    "                    \"streams\"\n",
    "                ][\n",
    "                    (\n",
    "                        int(\n",
    "                            ffmpeg.probe(f\"{base_path}/{weeks[w]}/{video}\")[\"format\"][\n",
    "                                \"nb_streams\"\n",
    "                            ]\n",
    "                        )\n",
    "                        - 1\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "        # set the week to \"True\" since it exists\n",
    "        # this is necessary as some weeks don't have data (yet)\n",
    "        week_filter[w] = True\n",
    "\n",
    "        # save list of values to variable arrays omitting NaN values\n",
    "        airpuff_on[w] = [x for x in data[w][\"Airpuff_on\"] if isnan(x) == False]\n",
    "        airpuff_off[w] = [x for x in data[w][\"Airpuff_off\"] if isnan(x) == False]\n",
    "\n",
    "        sucrose_on[w] = [x for x in data[w][\"Sucrose_on\"] if isnan(x) == False]\n",
    "        sucrose_off[w] = [x for x in data[w][\"Sucrose_off\"] if isnan(x) == False]\n",
    "\n",
    "        LED_on[w] = [x for x in data[w][\"LED590_on\"] if isnan(x) == False]\n",
    "        LED_off[w] = [x for x in data[w][\"LED590_off\"] if isnan(x) == False]\n",
    "\n",
    "        speaker_on[w] = [x for x in data[w][\"Speaker_on\"] if isnan(x) == False]\n",
    "        speaker_off[w] = [x for x in data[w][\"Speaker_off\"] if isnan(x) == False]\n",
    "\n",
    "        licks_on[w] = [x for x in data[w][\"Lick_on\"] if isnan(x) == False]\n",
    "        licks_off[w] = [x for x in data[w][\"Lick_off\"] if isnan(x) == False]\n",
    "        if week_filter[w]: print(\"\\tWeek:\", w, \": Date:\", week ,\"-- done\")\n",
    "        \n",
    "    # filter the variable arrays to be only the lenght of weeks with data\n",
    "    # this makes sure that we don't have a week of empty values in our variable arrays\n",
    "    weeks = np.array(weeks)[week_filter]\n",
    "    data = [d for i, d in enumerate(data) if week_filter[i]]\n",
    "    \n",
    "    airpuff_on = [d for i, d in enumerate(airpuff_on) if week_filter[i]]\n",
    "    airpuff_off = [d for i, d in enumerate(airpuff_off) if week_filter[i]]\n",
    "\n",
    "    sucrose_on = [d for i, d in enumerate(sucrose_on) if week_filter[i]]\n",
    "    sucrose_off = [d for i, d in enumerate(sucrose_off) if week_filter[i]]\n",
    "\n",
    "    LED_on = [d for i, d in enumerate(LED_on) if week_filter[i]]\n",
    "    LED_off = [d for i, d in enumerate(LED_off) if week_filter[i]]\n",
    "\n",
    "    speaker_on = [d for i, d in enumerate(speaker_on) if week_filter[i]]\n",
    "    speaker_off = [d for i, d in enumerate(speaker_off) if week_filter[i]]\n",
    "    \n",
    "    licks_on = [d for i, d in enumerate(licks_on) if week_filter[i]]\n",
    "    licks_off = [d for i, d in enumerate(licks_off) if week_filter[i]]\n",
    "\n",
    "    video_metadata = [d for i, d in enumerate(video_metadata) if week_filter[i]]\n",
    "    beh_metadata = [d for i, d in enumerate(beh_metadata) if week_filter[i]]\n",
    "    trialArray = [d for i, d in enumerate(trialArray) if week_filter[i]]\n",
    "    ITIArray = [d for i, d in enumerate(ITIArray) if week_filter[i]]\n",
    "    \n",
    "    # save the variable arrays to a dictionary with all the values\n",
    "    for v in [\n",
    "        \"airpuff_on\",\n",
    "        \"airpuff_off\",\n",
    "        \"sucrose_on\",\n",
    "        \"sucrose_off\",\n",
    "        \"LED_on\",\n",
    "        \"LED_off\",\n",
    "        \"speaker_on\",\n",
    "        \"speaker_off\",\n",
    "        \"licks_on\",\n",
    "        \"licks_off\",\n",
    "        \"video_metadata\",\n",
    "        \"beh_metadata\",\n",
    "        \"trialArray\",\n",
    "        \"ITIArray\"\n",
    "    ]:\n",
    "        exec(\"exprs[%s]['%s'] = %s\" % (m, v, v))\n",
    "        exec(\"del(%s)\" % (v))\n",
    "    print(mouse, \"-- complete\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning...\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning...\")\n",
    "del(base_path)\n",
    "del(data)\n",
    "del(data_path)\n",
    "del(js)\n",
    "del(js_file)\n",
    "del(csv)\n",
    "del(mouse)\n",
    "del(video)\n",
    "del(v)\n",
    "del(m)\n",
    "del(w)\n",
    "del(week_filter)\n",
    "del(week)\n",
    "del(n_weeks)\n",
    "del(weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSC009 -- starting\n",
      "\tWeek: 0 : File: 20211106_CSC009_plane1_-267.85.mp4.000_20211106_CSC009_plane1_-267.85.analysis.h5 -- done\n",
      "\tWeek: 1 : File: 20211111_CSC009_plane1_-289.0.mp4.000_20211111_CSC009_plane1_-289.0.analysis.h5 -- done\n",
      "\tWeek: 2 : File: 20211118_CSC009_plane1_-388.9.mp4.000_20211118_CSC009_plane1_-388.9.analysis.h5 -- done\n",
      "\tWeek: 3 : File: 20211125_CSC009_plane1_-311.475.mp4.000_20211125_CSC009_plane1_-311.475.analysis.h5 -- done\n",
      "\tWeek: 4 : File: 20211202_CSC009_plane1_-308.0.mp4.000_20211202_CSC009_plane1_-308.0.analysis.h5 -- done\n",
      "\tWeek: 5 : File: 20211209_CSC009_plane1_-282.9.mp4.000_20211209_CSC009_plane1_-282.9.analysis.h5 -- done\n",
      "\tWeek: 6 : File: 20211214_CSC009_plane1_-272.175.mp4.000_20211214_CSC009_plane1_-272.175.analysis.h5 -- done\n",
      "CSC009 -- complete\n",
      "CSC013 -- starting\n",
      "\tWeek: 0 : File: 20211104_CSC013_plane1_-538.875.mp4.000_20211104_CSC013_plane1_-538.875.analysis.h5 -- done\n",
      "\tWeek: 1 : File: 20211111_CSC013_plane1_-367.25.mp4.000_20211111_CSC013_plane1_-367.25.analysis.h5 -- done\n",
      "\tWeek: 2 : File: 20211118_CSC013_plane1_-749.075.mp4.000_20211118_CSC013_plane1_-749.075.analysis.h5 -- done\n",
      "\tWeek: 3 : File: 20211125_CSC013_plane1_-357.625.mp4.000_20211125_CSC013_plane1_-357.625.analysis.h5 -- done\n",
      "\tWeek: 4 : File: 20211202_CSC013_plane1_-727.1.mp4.000_20211202_CSC013_plane1_-727.1.analysis.h5 -- done\n",
      "\tWeek: 5 : File: 20211209_CSC013_plane1_-746.175.mp4.000_20211209_CSC013_plane1_-746.175.analysis.h5 -- done\n",
      "\tWeek: 6 : File: 20211214_CSC013_plane1_-362.075.mp4.000_20211214_CSC013_plane1_-362.075.analysis.h5 -- done\n",
      "CSC013 -- complete\n",
      "CSE008 -- starting\n",
      "\tWeek: 0 : File: 20211105_CSE008_plane1_-353.925.mp4.000_20211105_CSE008_plane1_-353.925.analysis.h5 -- done\n",
      "\tWeek: 1 : File: 20211112_CSE008_plane1_-368.0.mp4.000_20211112_CSE008_plane1_-368.0.analysis.h5 -- done\n",
      "\tWeek: 2 : File: 20211119_CSE008_plane1_-359.6.mp4.000_20211119_CSE008_plane1_-359.6.analysis.h5 -- done\n",
      "\tWeek: 3 : File: 20211126_CSE008_plane1_-357.9.mp4.000_20211126_CSE008_plane1_-357.9.analysis.h5 -- done\n",
      "\tWeek: 4 : File: 20211203_CSE008_plane1_-353.1.mp4.000_20211203_CSE008_plane1_-353.1.analysis.h5 -- done\n",
      "\tWeek: 5 : File: 20211210_CSE008_plane1_-692.725.mp4.000_20211210_CSE008_plane1_-692.725.analysis.h5 -- done\n",
      "\tWeek: 6 : File: 20211215_CSE008_plane1_-335.625.mp4.000_20211215_CSE008_plane1_-335.625.analysis.h5 -- done\n",
      "CSE008 -- complete\n",
      "CSE021 -- starting\n",
      "\tWeek: 0 : File: 20211113_CSE021_plane1_-331.825.mp4.000_20211113_CSE021_plane1_-331.825.analysis.h5 -- done\n",
      "\tWeek: 1 : File: 20211127_CSE021_plane1_-370.35.mp4.000_20211127_CSE021_plane1_-370.35.analysis.h5 -- done\n",
      "\tWeek: 2 : File: 20211204_CSE021_plane1_-268.525.mp4.000_20211204_CSE021_plane1_-268.525.analysis.h5 -- done\n",
      "\tWeek: 3 : File: 20211211_CSE021_plane1_-328.375.mp4.000_20211211_CSE021_plane1_-328.375.analysis.h5 -- done\n",
      "\tWeek: 4 : File: 20211216_CSE021_plane1_-733.45.mp4.000_20211216_CSE021_plane1_-733.45.analysis.h5 -- done\n",
      "CSE021 -- complete\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# change path to point to the SLEAP datasets\n",
    "if platform.system() == 'Darwin':\n",
    "    base_path = \"/Volumes/snlkt_lvhome/aehler/Projects/SLEAP-personal/videos/\"\n",
    "else:   \n",
    "    base_path = \"/nadata/snlkt/lvhome/aehler/Projects/SLEAP-personal/videos/\"\n",
    "os.chdir(base_path)\n",
    "\n",
    "# enumerate mice\n",
    "for m, mouse in enumerate(mice):\n",
    "    print(mouse, \"-- starting\")\n",
    "    \n",
    "    # get each SLEAP analysis file for the current mouse\n",
    "    weeks = glob.glob(f\"*{mouse}*\")\n",
    "    \n",
    "    # sort the SLEAP analysis files by date (from first occourance to last)\n",
    "    weeks.sort()\n",
    "    n_weeks = len(weeks)\n",
    "    week_filter = np.zeros(n_weeks, dtype=bool)\n",
    "\n",
    "    # create variable arrays with the length of weeks\n",
    "    datasets = [[] for _ in range(n_weeks)]\n",
    "    edge_inds = [[] for _ in range(n_weeks)]\n",
    "    edge_names = [[] for _ in range(n_weeks)]\n",
    "    instance_scores = [[] for _ in range(n_weeks)]\n",
    "    point_scores = [[] for _ in range(n_weeks)]\n",
    "    track_occupancy = [[] for _ in range(n_weeks)]\n",
    "    tracking_scores = [[] for _ in range(n_weeks)]\n",
    "    tracking_locations = [[] for _ in range(n_weeks)]\n",
    "    node_names = [[] for _ in range(n_weeks)]\n",
    "    video_metadata = [[] for _ in range(n_weeks)]\n",
    "    \n",
    "    # enumerate weeks\n",
    "    for w, week in enumerate(weeks):\n",
    "        \n",
    "        # concatenate the SLEAP analysis filename to the end of the base_path\n",
    "        filename = f\"{base_path}{weeks[w]}\"\n",
    "\n",
    "        # set the week to \"True\" since it exists\n",
    "        # this is necessary as some weeks don't have data (yet)\n",
    "        week_filter[w] = True\n",
    "        \n",
    "        # open the analysis file\n",
    "        with h5py.File(filename, \"r\") as f:\n",
    "            # with the analysis file open...\n",
    "            \n",
    "            # get each variable and store values\n",
    "            datasets[w] = list(f.keys())\n",
    "            tracking_locations[w] = fill_missing(f[\"tracks\"][:].T)\n",
    "            edge_inds[w] = f[\"edge_inds\"][:].T\n",
    "            edge_names[w] = f[\"edge_names\"][:]\n",
    "            instance_scores[w] = f[\"instance_scores\"][:].T\n",
    "            point_scores[w] = f[\"point_scores\"][:].T\n",
    "            track_occupancy[w] = f[\"track_occupancy\"][:]\n",
    "            tracking_scores[w] = f[\"tracking_scores\"][:].T\n",
    "            node_names[w] = [n.decode() for n in f[\"node_names\"][:]]\n",
    "        if week_filter[w]: print(\"\\tWeek:\", w, \": File:\", week,\"-- done\")\n",
    "            \n",
    "    # filter out the weeks without data\n",
    "    weeks = np.array(weeks)[week_filter]\n",
    "    datasets = [d for i, d in enumerate(datasets) if week_filter[i]]\n",
    "    tracking_locations = [d for i, d in enumerate(tracking_locations) if week_filter[i]]\n",
    "    edge_inds = [d for i, d in enumerate(edge_inds) if week_filter[i]]\n",
    "    edge_names = [d for i, d in enumerate(edge_names) if week_filter[i]]\n",
    "    instance_scores = [d for i, d in enumerate(instance_scores) if week_filter[i]]\n",
    "    point_scores = [d for i, d in enumerate(point_scores) if week_filter[i]]\n",
    "    track_occupancy = [d for i, d in enumerate(track_occupancy) if week_filter[i]]\n",
    "    tracking_scores = [d for i, d in enumerate(tracking_scores) if week_filter[i]]\n",
    "    node_names = [d for i, d in enumerate(node_names) if week_filter[i]]\n",
    "\n",
    "    # save the variable arrays to a dictionary with all the values \n",
    "    for v in [\n",
    "        \"datasets\",\n",
    "        \"tracking_locations\",\n",
    "        \"node_names\",\n",
    "        \"edge_names\",\n",
    "        \"edge_inds\",\n",
    "        \"instance_scores\",\n",
    "        \"point_scores\",\n",
    "        \"track_occupancy\",\n",
    "        \"tracking_scores\",\n",
    "    ]:\n",
    "        exec(\"exprs[%s]['%s'] = %s\" % (m, v, v))\n",
    "        exec(\"del(%s)\" % (v))\n",
    "    print(mouse, \"-- complete\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['20211113_CSE021_plane1_-331.825.mp4.000_20211113_CSE021_plane1_-331.825.analysis.h5',\n",
       "       '20211127_CSE021_plane1_-370.35.mp4.000_20211127_CSE021_plane1_-370.35.analysis.h5',\n",
       "       '20211204_CSE021_plane1_-268.525.mp4.000_20211204_CSE021_plane1_-268.525.analysis.h5',\n",
       "       '20211211_CSE021_plane1_-328.375.mp4.000_20211211_CSE021_plane1_-328.375.analysis.h5',\n",
       "       '20211216_CSE021_plane1_-733.45.mp4.000_20211216_CSE021_plane1_-733.45.analysis.h5'],\n",
       "      dtype='<U83')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning...\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning...\")\n",
    "del(base_path)\n",
    "del(f)\n",
    "del(filename)\n",
    "del(mouse)\n",
    "del(m)\n",
    "del(n_weeks)\n",
    "del(w)\n",
    "del(week)\n",
    "del(v)\n",
    "del(weeks)\n",
    "del(week_filter)\n",
    "del(video_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSC009 -- starting\n",
      "\tWeek: 0 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 1 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 2 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 3 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 4 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 5 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 6 : ms/frame: 33.990482664853836 -- done\n",
      "CSC009 -- complete\n",
      "CSC013 -- starting\n",
      "\tWeek: 0 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 1 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 2 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 3 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 4 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 5 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 6 : ms/frame: 33.990482664853836 -- done\n",
      "CSC013 -- complete\n",
      "CSE008 -- starting\n",
      "\tWeek: 0 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 1 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 2 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 3 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 4 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 5 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 6 : ms/frame: 33.990482664853836 -- done\n",
      "CSE008 -- complete\n",
      "CSE021 -- starting\n",
      "\tWeek: 0 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 1 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 2 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 3 : ms/frame: 33.990482664853836 -- done\n",
      "\tWeek: 4 : ms/frame: 33.990482664853836 -- done\n",
      "CSE021 -- complete\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# set original data path\n",
    "if platform.system() == 'Darwin':\n",
    "    data_path = f\"/Volumes/specialk_cs/2p/raw/\"\n",
    "else:   \n",
    "    data_path = f\"/nadata/snlkt/specialk_cs/2p/raw/\"\n",
    "\n",
    "# enumerate each mouse\n",
    "for m, mouse in enumerate(mice):\n",
    "    print(mouse, \"-- starting\")\n",
    "\n",
    "    # get each week folder from mouse base directory\n",
    "    _, weeks, _ = next(os.walk(data_path + mouse), ([], [], []))\n",
    "\n",
    "    # complete the path for each week in order of completion\n",
    "    # (i.e. week 0 is the first week, week 1 the second)\n",
    "    weeks.sort()\n",
    "    n_weeks = len(weeks)\n",
    "    week_filter = np.zeros(n_weeks, dtype=bool)\n",
    "\n",
    "    # enumerate each (new) variable dictionary (using exec function for reduncacy)\n",
    "    for v in [\n",
    "        \"mouse_list\",\n",
    "        \"week_list\",\n",
    "        \"frame_list\",\n",
    "        \"timestamps\",\n",
    "    ]:\n",
    "        # create a list with the length # of weeks for each varaible\n",
    "        executable = compile(\"%s = %s\" % (v, [[] for _ in range(n_weeks)]), 'casting', 'exec')\n",
    "        exec(executable, globals(), locals())\n",
    "\n",
    "    for v in [\n",
    "        \"upper_eye_x\",\n",
    "        \"upper_eye_y\",\n",
    "        \"lower_eye_x\",\n",
    "        \"lower_eye_y\",\n",
    "        \"upper_ear_x\",\n",
    "        \"upper_ear_y\",\n",
    "        \"lower_ear_x\",\n",
    "        \"lower_ear_y\",\n",
    "        \"outer_ear_x\",\n",
    "        \"outer_ear_y\",\n",
    "        \"upper_whisker_x\",\n",
    "        \"upper_whisker_y\",\n",
    "        \"outer_whisker_x\",\n",
    "        \"outer_whisker_y\",\n",
    "        \"lower_whisker_x\",\n",
    "        \"lower_whisker_y\",\n",
    "        \"upper_mouth_x\",\n",
    "        \"upper_mouth_y\",\n",
    "        \"outer_mouth_x\",\n",
    "        \"outer_mouth_y\",\n",
    "        \"lower_mouth_x\",\n",
    "        \"lower_mouth_y\",\n",
    "        \"inner_nostril_x\",\n",
    "        \"inner_nostril_y\",\n",
    "        \"outer_nostril_x\",\n",
    "        \"outer_nostril_y\"\n",
    "    ]:\n",
    "        # create a list with the length # of weeks for each varaible\n",
    "        code = compile(f\"{v} = [ _ for _ in range({n_weeks})]\", \"assign\", \"exec\")\n",
    "        exec(code, globals(), locals())\n",
    "\n",
    "    # iterate each frame in the SLEAP tracks\n",
    "    for w in range(0, len(exprs[m][\"tracking_locations\"]), 1):\n",
    "        \n",
    "        # if the video exists and is processed\n",
    "        if type(exprs[m][\"video_metadata\"][w]) == type(dict()):\n",
    "\n",
    "            week_filter[w] = True\n",
    "\n",
    "            # calculate miliseconds per frame based on the video metadata\n",
    "            miliseconds_per_frame = (\n",
    "                eval(exprs[m][\"video_metadata\"][w].get(\"avg_frame_rate\")) / 1000\n",
    "            ) ** -1\n",
    "            \n",
    "            # enumerate each node (or point) in the SLEAP tracks\n",
    "            for i, name in enumerate(exprs[m].get(\"node_names\")[w]):\n",
    "                \n",
    "                # break down the complex 4D array into 1D arrays of x and y values\n",
    "                exec(\n",
    "                    \"%s_x[%s] = np.array(%s)\" % (name.replace(\" \", \"_\"), w, exprs[m]['tracking_locations'][w][:, i, 0, 0].tolist()), \n",
    "                    globals(), locals()\n",
    "                )\n",
    "                exec(\n",
    "                    \"%s_y[%s] = np.array(%s)\" % (name.replace(\" \", \"_\"), w, exprs[m]['tracking_locations'][w][:, i, 1, 0].tolist()), \n",
    "                    globals(), locals()\n",
    "                )\n",
    "\n",
    "                # iterate each frame\n",
    "                for f in range(len(exprs[m][\"tracking_locations\"][w][:, i, 0, 0].tolist())):\n",
    "                    \n",
    "                    # label frame with the specific mouse, week, frame, and timestamp\n",
    "                    mouse_list[w].append(mouse)\n",
    "                    week_list[w].append(w)\n",
    "                    frame_list[w].append(f)\n",
    "                    miliseconds = f * miliseconds_per_frame\n",
    "                    timestamps[w].append(miliseconds)\n",
    "                \n",
    "        print(\"\\tWeek:\", w, \": ms/frame:\", miliseconds_per_frame, \"-- done\") if week_filter[w] else print(f\"No data for mouse {mice[m]} on week {w}\")\n",
    "\n",
    "    # filter out the weeks without data (using exec function for redundancy)\n",
    "    for v in [\n",
    "        \"mouse_list\",\n",
    "        \"week_list\",\n",
    "        \"frame_list\",\n",
    "        \"timestamps\",\n",
    "        \"upper_eye_x\",\n",
    "        \"upper_eye_y\",\n",
    "        \"lower_eye_x\",\n",
    "        \"lower_eye_y\",\n",
    "        \"upper_ear_x\",\n",
    "        \"upper_ear_y\",\n",
    "        \"lower_ear_x\",\n",
    "        \"lower_ear_y\",\n",
    "        \"outer_ear_x\",\n",
    "        \"outer_ear_y\",\n",
    "        \"upper_whisker_x\",\n",
    "        \"upper_whisker_y\",\n",
    "        \"outer_whisker_x\",\n",
    "        \"outer_whisker_y\",\n",
    "        \"lower_whisker_x\",\n",
    "        \"lower_whisker_y\",\n",
    "        \"upper_mouth_x\",\n",
    "        \"upper_mouth_y\",\n",
    "        \"outer_mouth_x\",\n",
    "        \"outer_mouth_y\",\n",
    "        \"lower_mouth_x\",\n",
    "        \"lower_mouth_y\",\n",
    "        \"inner_nostril_x\",\n",
    "        \"inner_nostril_y\",\n",
    "        \"outer_nostril_x\",\n",
    "        \"outer_nostril_y\",\n",
    "    ]:\n",
    "        executable = compile(\"%s = [d for i, d in enumerate(%s) if week_filter[i]]\" % (v, v),  'filter', 'exec')\n",
    "        exec(executable, globals(), locals())\n",
    "        \n",
    "    # save the variable arrays to a dictionary with all the values \n",
    "    for v in [\n",
    "        \"mouse_list\",\n",
    "        \"week_list\",\n",
    "        \"frame_list\",\n",
    "        \"timestamps\",\n",
    "        \"upper_eye_x\",\n",
    "        \"upper_eye_y\",\n",
    "        \"lower_eye_x\",\n",
    "        \"lower_eye_y\",\n",
    "        \"upper_ear_x\",\n",
    "        \"upper_ear_y\",\n",
    "        \"lower_ear_x\",\n",
    "        \"lower_ear_y\",\n",
    "        \"outer_ear_x\",\n",
    "        \"outer_ear_y\",\n",
    "        \"upper_whisker_x\",\n",
    "        \"upper_whisker_y\",\n",
    "        \"outer_whisker_x\",\n",
    "        \"outer_whisker_y\",\n",
    "        \"lower_whisker_x\",\n",
    "        \"lower_whisker_y\",\n",
    "        \"upper_mouth_x\",\n",
    "        \"upper_mouth_y\",\n",
    "        \"outer_mouth_x\",\n",
    "        \"outer_mouth_y\",\n",
    "        \"lower_mouth_x\",\n",
    "        \"lower_mouth_y\",\n",
    "        \"inner_nostril_x\",\n",
    "        \"inner_nostril_y\",\n",
    "        \"outer_nostril_x\",\n",
    "        \"outer_nostril_y\",\n",
    "    ]:\n",
    "        exec(\"exprs[%s]['%s'] = %s\" % (m, v, v))\n",
    "        exec(\"del(%s)\" % (v))\n",
    "    print(mouse, \"-- complete\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning...\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning...\")\n",
    "del(executable)\n",
    "del(i)\n",
    "del(m)\n",
    "del(miliseconds)\n",
    "del(miliseconds_per_frame)\n",
    "del(mouse)\n",
    "del(name)\n",
    "del(v)\n",
    "del(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26445, 20446, 28842, 19956, 19311, 23443, 16946, 23768, 19458, 20543, 29868, 20178, 21168, 20816, 18355, 17563, 17954, 16747, 29538, 21888, 16062, 26749, 29100, 25018, 16423, 19926, 27223, 20778, 23373, 20540, 26136, 17530, 29532, 26575, 26683, 18395, 27572, 15756, 15036, 28532, 24587, 28786, 15837, 22589, 18565, 26543, 17904, 21224, 29524, 21836, 24543, 29805, 15999, 27729, 21672, 15360, 22920, 18537, 26691, 20364]\n"
     ]
    }
   ],
   "source": [
    "print(exprs[0]['ITIArray'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSC009 -- starting\n",
      "\tWeek: 0 starting...\n",
      "\t\tWeek: 0 processing...\n",
      "\tWeek: 0 ending...\n",
      "\t\tWeek: 0 Num Trials: 60 -- done\n",
      "\tWeek: 1 starting...\n",
      "\t\tWeek: 1 processing...\n",
      "\tWeek: 1 ending...\n",
      "\t\tWeek: 1 Num Trials: 60 -- done\n",
      "\tWeek: 2 starting...\n",
      "\t\tWeek: 2 processing...\n",
      "\tWeek: 2 ending...\n",
      "\t\tWeek: 2 Num Trials: 60 -- done\n",
      "\tWeek: 3 starting...\n",
      "\t\tWeek: 3 processing...\n",
      "\tWeek: 3 ending...\n",
      "\t\tWeek: 3 Num Trials: 60 -- done\n",
      "\tWeek: 4 starting...\n",
      "\t\tWeek: 4 processing...\n",
      "\tWeek: 4 ending...\n",
      "\t\tWeek: 4 Num Trials: 60 -- done\n",
      "\tWeek: 5 starting...\n",
      "\t\tWeek: 5 processing...\n",
      "\tWeek: 5 ending...\n",
      "\t\tWeek: 5 Num Trials: 60 -- done\n",
      "\tWeek: 6 starting...\n",
      "\t\tWeek: 6 processing...\n",
      "\tWeek: 6 ending...\n",
      "\t\tWeek: 6 Num Trials: 60 -- done\n",
      "CSC009 -- complete\n",
      "CSC013 -- starting\n",
      "\tWeek: 0 starting...\n",
      "\t\tWeek: 0 processing...\n",
      "\tWeek: 0 ending...\n",
      "\t\tWeek: 0 Num Trials: 60 -- done\n",
      "\tWeek: 1 starting...\n",
      "\t\tWeek: 1 processing...\n",
      "\tWeek: 1 ending...\n",
      "\t\tWeek: 1 Num Trials: 60 -- done\n",
      "\tWeek: 2 starting...\n",
      "\t\tWeek: 2 processing...\n",
      "\tWeek: 2 ending...\n",
      "\t\tWeek: 2 Num Trials: 60 -- done\n",
      "\tWeek: 3 starting...\n",
      "\t\tWeek: 3 processing...\n",
      "\tWeek: 3 ending...\n",
      "\t\tWeek: 3 Num Trials: 60 -- done\n",
      "\tWeek: 4 starting...\n",
      "\t\tWeek: 4 processing...\n",
      "\tWeek: 4 ending...\n",
      "\t\tWeek: 4 Num Trials: 60 -- done\n",
      "\tWeek: 5 starting...\n",
      "\t\tWeek: 5 processing...\n",
      "\tWeek: 5 ending...\n",
      "\t\tWeek: 5 Num Trials: 60 -- done\n",
      "\tWeek: 6 starting...\n",
      "\t\tWeek: 6 processing...\n",
      "\tWeek: 6 ending...\n",
      "\t\tWeek: 6 Num Trials: 60 -- done\n",
      "CSC013 -- complete\n",
      "CSE008 -- starting\n",
      "\tWeek: 0 starting...\n",
      "\t\tWeek: 0 processing...\n",
      "\tWeek: 0 ending...\n",
      "\t\tWeek: 0 Num Trials: 60 -- done\n",
      "\tWeek: 1 starting...\n",
      "\t\tWeek: 1 processing...\n",
      "\tWeek: 1 ending...\n",
      "\t\tWeek: 1 Num Trials: 60 -- done\n",
      "\tWeek: 2 starting...\n",
      "\t\tWeek: 2 processing...\n",
      "\tWeek: 2 ending...\n",
      "\t\tWeek: 2 Num Trials: 60 -- done\n",
      "\tWeek: 3 starting...\n",
      "\t\tWeek: 3 processing...\n",
      "\tWeek: 3 ending...\n",
      "\t\tWeek: 3 Num Trials: 60 -- done\n",
      "\tWeek: 4 starting...\n",
      "\t\tWeek: 4 processing...\n",
      "\tWeek: 4 ending...\n",
      "\t\tWeek: 4 Num Trials: 60 -- done\n",
      "\tWeek: 5 starting...\n",
      "\t\tWeek: 5 processing...\n",
      "\tWeek: 5 ending...\n",
      "\t\tWeek: 5 Num Trials: 60 -- done\n",
      "\tWeek: 6 starting...\n",
      "\t\tWeek: 6 processing...\n",
      "\tWeek: 6 ending...\n",
      "\t\tWeek: 6 Num Trials: 60 -- done\n",
      "CSE008 -- complete\n",
      "CSE021 -- starting\n",
      "\tWeek: 0 starting...\n",
      "\t\tWeek: 0 processing...\n",
      "\tWeek: 0 ending...\n",
      "\t\tWeek: 0 Num Trials: 60 -- done\n",
      "\tWeek: 1 starting...\n",
      "\t\tWeek: 1 processing...\n",
      "\tWeek: 1 ending...\n",
      "\t\tWeek: 1 Num Trials: 60 -- done\n",
      "\tWeek: 2 starting...\n",
      "\t\tWeek: 2 processing...\n",
      "\tWeek: 2 ending...\n",
      "\t\tWeek: 2 Num Trials: 60 -- done\n",
      "\tWeek: 3 starting...\n",
      "\t\tWeek: 3 processing...\n",
      "\tWeek: 3 ending...\n",
      "\t\tWeek: 3 Num Trials: 60 -- done\n",
      "\tWeek: 4 starting...\n",
      "\t\tWeek: 4 processing...\n",
      "\tWeek: 4 ending...\n",
      "\t\tWeek: 4 Num Trials: 60 -- done\n",
      "CSE021 -- complete\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "if platform.system() == 'Darwin':\n",
    "    data_path = f\"/Volumes/specialk_cs/2p/raw/\"\n",
    "else:\n",
    "    data_path = f\"/nadata/snlkt/specialk_cs/2p/raw/\"\n",
    "\n",
    "# create trial data\n",
    "for m, mouse in enumerate(mice):\n",
    "\n",
    "    print(mouse, \"-- starting\")\n",
    "\n",
    "    # complete the path for each week in order of existence in exprs\n",
    "    # (i.e. week 0 is the first week, week 1 the second)\n",
    "    n_weeks = len(exprs[m][\"timestamps\"])\n",
    "\n",
    "    # create variable arrays with the length of weeks\n",
    "    week_filter = np.zeros(n_weeks, dtype=bool)\n",
    "    data = [[] for _ in range(n_weeks)]\n",
    "\n",
    "    for w in range(n_weeks):\n",
    "\n",
    "        print(f\"\\tWeek: {w} starting...\")\n",
    "\n",
    "        led = 0\n",
    "        speaker = 0\n",
    "        trial_type = [\n",
    "            \"Airpuff\", \"Sucrose\", \"Airpuff catch\", \"Sucrose catch\",\n",
    "            \"Airpuff with LED\", \"Sucrose with LED\", \"LED Only\"\n",
    "        ]\n",
    "\n",
    "        dataframe = [\n",
    "            pd.DataFrame() for _ in range(len(exprs[m]['trialArray'][w]))\n",
    "        ]\n",
    "\n",
    "        led_start_array = reduce_led(exprs[m]['LED_on'][w])\n",
    "        led_end_array = reduce_led(exprs[m]['LED_off'][w])\n",
    "\n",
    "        exprs[m]['timestamps'][w] = np.array(exprs[m]['timestamps'][w])\n",
    "\n",
    "        # if the video data has been processed\n",
    "        if w < len(exprs[m][\"timestamps\"]):\n",
    "\n",
    "            print(f\"\\t\\tWeek: {w} processing...\")\n",
    "\n",
    "            week_filter[w] = True\n",
    "\n",
    "            for i, trial in enumerate(exprs[m]['trialArray'][w]):\n",
    "\n",
    "                if trial in [0, 1, 2, 3, 4, 5]:\n",
    "\n",
    "                    # element to which nearest value is to be found\n",
    "                    start: float = exprs[m]['speaker_on'][w][speaker] - 10000\n",
    "                    end: float = exprs[m]['speaker_on'][w][speaker] + 13000\n",
    "\n",
    "                    # speaker index\n",
    "                    speaker = speaker + 1\n",
    "\n",
    "                    # calculate the difference array\n",
    "                    start_difference_array = np.absolute(\n",
    "                        exprs[m]['timestamps'][w] - start)\n",
    "                    end_difference_array = np.absolute(\n",
    "                        exprs[m]['timestamps'][w] - end)\n",
    "\n",
    "                    # find the index of minimum element from the array\n",
    "                    start_index = start_difference_array.argmin()\n",
    "                    end_index = end_difference_array.argmin()\n",
    "\n",
    "                    # make a new dataframe for each trial\n",
    "                    dataframe[i] = pd.DataFrame(\n",
    "                        {\n",
    "                            \"mouse_list\":\n",
    "                            exprs[m]['mouse_list'][w][start_index:end_index +\n",
    "                                                        1],\n",
    "                            \"week_list\":\n",
    "                            exprs[m]['week_list'][w][start_index:end_index +\n",
    "                                                        1],\n",
    "                            \"frame_list\":\n",
    "                            exprs[m]['frame_list'][w][start_index:end_index +\n",
    "                                                        1],\n",
    "                            \"timestamps\":\n",
    "                            exprs[m]['timestamps'][w][start_index:end_index +\n",
    "                                                        1],\n",
    "                            \"trial_num\":\n",
    "                            [i for _ in range(start_index, end_index + 1)],\n",
    "                            \"trial_idx\":\n",
    "                            [trial for _ in range(start_index, end_index + 1)],\n",
    "                            \"trial_type\": [\n",
    "                                trial_type[trial]\n",
    "                                for _ in range(start_index, end_index + 1)\n",
    "                            ],\n",
    "                            \"upper_eye_x\":\n",
    "                            exprs[m]['upper_eye_x'][w][start_index:end_index +\n",
    "                                                        1],\n",
    "                            \"upper_eye_y\":\n",
    "                            exprs[m]['upper_eye_y'][w][start_index:end_index +\n",
    "                                                        1],\n",
    "                            \"lower_eye_x\":\n",
    "                            exprs[m]['lower_eye_x'][w][start_index:end_index +\n",
    "                                                        1],\n",
    "                            \"lower_eye_y\":\n",
    "                            exprs[m]['lower_eye_y'][w][start_index:end_index +\n",
    "                                                        1],\n",
    "                            \"upper_ear_x\":\n",
    "                            exprs[m]['upper_ear_x'][w][start_index:end_index +\n",
    "                                                        1],\n",
    "                            \"upper_ear_y\":\n",
    "                            exprs[m]['upper_ear_y'][w][start_index:end_index +\n",
    "                                                        1],\n",
    "                            \"lower_ear_x\":\n",
    "                            exprs[m]['lower_ear_x'][w][start_index:end_index +\n",
    "                                                        1],\n",
    "                            \"lower_ear_y\":\n",
    "                            exprs[m]['lower_ear_y'][w][start_index:end_index +\n",
    "                                                        1],\n",
    "                            \"outer_ear_x\":\n",
    "                            exprs[m]['outer_ear_x'][w][start_index:end_index +\n",
    "                                                        1],\n",
    "                            \"outer_ear_y\":\n",
    "                            exprs[m]['outer_ear_y'][w][start_index:end_index +\n",
    "                                                        1],\n",
    "                            \"upper_whisker_x\":\n",
    "                            exprs[m]['upper_whisker_x'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"upper_whisker_y\":\n",
    "                            exprs[m]['upper_whisker_y'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"outer_whisker_x\":\n",
    "                            exprs[m]['outer_whisker_x'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"outer_whisker_y\":\n",
    "                            exprs[m]['outer_whisker_y'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"lower_whisker_x\":\n",
    "                            exprs[m]['lower_whisker_x'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"lower_whisker_y\":\n",
    "                            exprs[m]['lower_whisker_y'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"upper_mouth_x\":\n",
    "                            exprs[m]['upper_mouth_x'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"upper_mouth_y\":\n",
    "                            exprs[m]['upper_mouth_y'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"outer_mouth_x\":\n",
    "                            exprs[m]['outer_mouth_x'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"outer_mouth_y\":\n",
    "                            exprs[m]['outer_mouth_y'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"lower_mouth_x\":\n",
    "                            exprs[m]['lower_mouth_x'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"lower_mouth_y\":\n",
    "                            exprs[m]['lower_mouth_y'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"inner_nostril_x\":\n",
    "                            exprs[m]['inner_nostril_x'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"inner_nostril_y\":\n",
    "                            exprs[m]['inner_nostril_y'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"outer_nostril_x\":\n",
    "                            exprs[m]['outer_nostril_x'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"outer_nostril_y\":\n",
    "                            exprs[m]['outer_nostril_y'][w]\n",
    "                            [start_index:end_index + 1]\n",
    "                        },\n",
    "                        columns=[\n",
    "                            \"mouse_list\", \"week_list\", \"frame_list\",\n",
    "                            \"timestamps\", \"trial_num\", \"trial_idx\",\n",
    "                            \"trial_type\", \"upper_eye_x\", \"upper_eye_y\",\n",
    "                            \"lower_eye_x\", \"lower_eye_y\", \"upper_ear_x\",\n",
    "                            \"upper_ear_y\", \"lower_ear_x\", \"lower_ear_y\",\n",
    "                            \"outer_ear_x\", \"outer_ear_y\", \"upper_whisker_x\",\n",
    "                            \"upper_whisker_y\", \"outer_whisker_x\",\n",
    "                            \"outer_whisker_y\", \"lower_whisker_x\",\n",
    "                            \"lower_whisker_y\", \"upper_mouth_x\",\n",
    "                            \"upper_mouth_y\", \"outer_mouth_x\", \"outer_mouth_y\",\n",
    "                            \"lower_mouth_x\", \"lower_mouth_y\",\n",
    "                            \"inner_nostril_x\", \"inner_nostril_y\",\n",
    "                            \"outer_nostril_x\", \"outer_nostril_y\"\n",
    "                        ],\n",
    "                        index=[j for j in range(start_index, end_index + 1)])\n",
    "\n",
    "                    if trial in [4, 5]:\n",
    "                        led = led + 1\n",
    "\n",
    "                if trial == 6:\n",
    "\n",
    "                    start = led_start_array[led] - 10000\n",
    "                    end = led_start_array[led] + 13000\n",
    "\n",
    "                    # calculate the difference array\n",
    "                    start_difference_array = np.absolute(\n",
    "                        exprs[m]['timestamps'][w] - start)\n",
    "                    end_difference_array = np.absolute(\n",
    "                        exprs[m]['timestamps'][w] - end)\n",
    "\n",
    "                    led = led + 1\n",
    "\n",
    "                    # find the index of minimum element from the array\n",
    "                    start_index = start_difference_array.argmin()\n",
    "                    end_index = end_difference_array.argmin()\n",
    "\n",
    "                    # make a new dataframe for each trial\n",
    "                    dataframe[i] = pd.DataFrame(\n",
    "                        {\n",
    "                            \"mouse_list\":\n",
    "                            exprs[m]['mouse_list'][w][start_index:end_index +\n",
    "                                                      1],\n",
    "                            \"week_list\":\n",
    "                            exprs[m]['week_list'][w][start_index:end_index +\n",
    "                                                     1],\n",
    "                            \"frame_list\":\n",
    "                            exprs[m]['frame_list'][w][start_index:end_index +\n",
    "                                                      1],\n",
    "                            \"timestamps\":\n",
    "                            exprs[m]['timestamps'][w][start_index:end_index +\n",
    "                                                      1],\n",
    "                            \"trial_num\":\n",
    "                            [i for _ in range(start_index, end_index + 1)],\n",
    "                            \"trial_idx\":\n",
    "                            [trial for _ in range(start_index, end_index + 1)],\n",
    "                            \"trial_type\": [\n",
    "                                trial_type[trial]\n",
    "                                for _ in range(start_index, end_index + 1)\n",
    "                            ],\n",
    "                            \"upper_eye_x\":\n",
    "                            exprs[m]['upper_eye_x'][w][start_index:end_index +\n",
    "                                                       1],\n",
    "                            \"upper_eye_y\":\n",
    "                            exprs[m]['upper_eye_y'][w][start_index:end_index +\n",
    "                                                       1],\n",
    "                            \"lower_eye_x\":\n",
    "                            exprs[m]['lower_eye_x'][w][start_index:end_index +\n",
    "                                                       1],\n",
    "                            \"lower_eye_y\":\n",
    "                            exprs[m]['lower_eye_y'][w][start_index:end_index +\n",
    "                                                       1],\n",
    "                            \"upper_ear_x\":\n",
    "                            exprs[m]['upper_ear_x'][w][start_index:end_index +\n",
    "                                                       1],\n",
    "                            \"upper_ear_y\":\n",
    "                            exprs[m]['upper_ear_y'][w][start_index:end_index +\n",
    "                                                       1],\n",
    "                            \"lower_ear_x\":\n",
    "                            exprs[m]['lower_ear_x'][w][start_index:end_index +\n",
    "                                                       1],\n",
    "                            \"lower_ear_y\":\n",
    "                            exprs[m]['lower_ear_y'][w][start_index:end_index +\n",
    "                                                       1],\n",
    "                            \"outer_ear_x\":\n",
    "                            exprs[m]['outer_ear_x'][w][start_index:end_index +\n",
    "                                                       1],\n",
    "                            \"outer_ear_y\":\n",
    "                            exprs[m]['outer_ear_y'][w][start_index:end_index +\n",
    "                                                       1],\n",
    "                            \"upper_whisker_x\":\n",
    "                            exprs[m]['upper_whisker_x'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"upper_whisker_y\":\n",
    "                            exprs[m]['upper_whisker_y'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"outer_whisker_x\":\n",
    "                            exprs[m]['outer_whisker_x'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"outer_whisker_y\":\n",
    "                            exprs[m]['outer_whisker_y'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"lower_whisker_x\":\n",
    "                            exprs[m]['lower_whisker_x'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"lower_whisker_y\":\n",
    "                            exprs[m]['lower_whisker_y'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"upper_mouth_x\":\n",
    "                            exprs[m]['upper_mouth_x'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"upper_mouth_y\":\n",
    "                            exprs[m]['upper_mouth_y'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"outer_mouth_x\":\n",
    "                            exprs[m]['outer_mouth_x'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"outer_mouth_y\":\n",
    "                            exprs[m]['outer_mouth_y'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"lower_mouth_x\":\n",
    "                            exprs[m]['lower_mouth_x'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"lower_mouth_y\":\n",
    "                            exprs[m]['lower_mouth_y'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"inner_nostril_x\":\n",
    "                            exprs[m]['inner_nostril_x'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"inner_nostril_y\":\n",
    "                            exprs[m]['inner_nostril_y'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"outer_nostril_x\":\n",
    "                            exprs[m]['outer_nostril_x'][w]\n",
    "                            [start_index:end_index + 1],\n",
    "                            \"outer_nostril_y\":\n",
    "                            exprs[m]['outer_nostril_y'][w]\n",
    "                            [start_index:end_index + 1]\n",
    "                        },\n",
    "                        columns=[\n",
    "                            \"mouse_list\", \"week_list\", \"frame_list\",\n",
    "                            \"timestamps\", \"trial_num\", \"trial_idx\",\n",
    "                            \"trial_type\", \"upper_eye_x\", \"upper_eye_y\",\n",
    "                            \"lower_eye_x\", \"lower_eye_y\", \"upper_ear_x\",\n",
    "                            \"upper_ear_y\", \"lower_ear_x\", \"lower_ear_y\",\n",
    "                            \"outer_ear_x\", \"outer_ear_y\", \"upper_whisker_x\",\n",
    "                            \"upper_whisker_y\", \"outer_whisker_x\",\n",
    "                            \"outer_whisker_y\", \"lower_whisker_x\",\n",
    "                            \"lower_whisker_y\", \"upper_mouth_x\",\n",
    "                            \"upper_mouth_y\", \"outer_mouth_x\", \"outer_mouth_y\",\n",
    "                            \"lower_mouth_x\", \"lower_mouth_y\",\n",
    "                            \"inner_nostril_x\", \"inner_nostril_y\",\n",
    "                            \"outer_nostril_x\", \"outer_nostril_y\"\n",
    "                        ],\n",
    "                        index=[j for j in range(start_index, end_index + 1)])\n",
    "\n",
    "        print(f\"\\tWeek: {w} ending...\")\n",
    "\n",
    "        dataframe = [\n",
    "            d for i, d in enumerate(dataframe)\n",
    "            if type(dataframe[i]) == type(pd.DataFrame())\n",
    "        ]\n",
    "\n",
    "        data[w] = pd.concat(dataframe, keys=[i for i in range(len(dataframe))])\n",
    "\n",
    "        if week_filter[w]:\n",
    "            print(\"\\t\\tWeek:\", w, \"Num Trials:\", len(dataframe), \"-- done\")\n",
    "\n",
    "        del (dataframe)\n",
    "\n",
    "    data = [d for i, d in enumerate(data) if week_filter[i]]\n",
    "\n",
    "    if len(data) > 0:\n",
    "        data = pd.concat(data, keys=[w for w in range(len(data))]) \n",
    "        exprs[m]['trial_data_by_mouse'] = data.dropna(how=\"any\", subset=[\"upper_eye_x\", \"upper_eye_y\", \"lower_eye_x\", \"lower_eye_y\", \"upper_ear_x\", \"upper_ear_y\", \"lower_ear_x\", \"lower_ear_y\", \"outer_ear_x\", \"outer_ear_y\", \"upper_whisker_x\", \"upper_whisker_y\", \"outer_whisker_x\", \"outer_whisker_y\", \"lower_whisker_x\", \"lower_whisker_y\", \"upper_mouth_x\", \"upper_mouth_y\", \"outer_mouth_x\", \"outer_mouth_y\", \"lower_mouth_x\", \"lower_mouth_y\", \"inner_nostril_x\", \"inner_nostril_y\", \"outer_nostril_x\", \"outer_nostril_y\"])\n",
    "    \n",
    "    del(data)\n",
    "\n",
    "    print(mouse, \"-- complete\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tWeek: 0 Num columns: 29 -- done\n",
      "\tWeek: 1 Num columns: 29 -- done\n",
      "\tWeek: 2 Num columns: 29 -- done\n",
      "\tWeek: 3 Num columns: 29 -- done\n",
      "\tWeek: 4 Num columns: 29 -- done\n",
      "\tWeek: 5 Num columns: 29 -- done\n",
      "\tWeek: 6 Num columns: 29 -- done\n",
      "CSC009 -- complete\n",
      "\tWeek: 0 Num columns: 29 -- done\n",
      "\tWeek: 1 Num columns: 29 -- done\n",
      "\tWeek: 2 Num columns: 29 -- done\n",
      "\tWeek: 3 Num columns: 29 -- done\n",
      "\tWeek: 4 Num columns: 29 -- done\n",
      "\tWeek: 5 Num columns: 29 -- done\n",
      "\tWeek: 6 Num columns: 29 -- done\n",
      "CSC013 -- complete\n",
      "\tWeek: 0 Num columns: 29 -- done\n",
      "\tWeek: 1 Num columns: 29 -- done\n",
      "\tWeek: 2 Num columns: 29 -- done\n",
      "\tWeek: 3 Num columns: 29 -- done\n",
      "\tWeek: 4 Num columns: 29 -- done\n",
      "\tWeek: 5 Num columns: 29 -- done\n",
      "\tWeek: 6 Num columns: 29 -- done\n",
      "CSE008 -- complete\n",
      "\tWeek: 0 Num columns: 29 -- done\n",
      "\tWeek: 1 Num columns: 29 -- done\n",
      "\tWeek: 2 Num columns: 29 -- done\n",
      "\tWeek: 3 Num columns: 29 -- done\n",
      "\tWeek: 4 Num columns: 29 -- done\n",
      "CSE021 -- complete\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# create data frame of weekly data\n",
    "columns = [\n",
    "    \"mouse_list\", \"week_list\", \"frame_list\", \"upper_eye_x\", \"upper_eye_y\",\n",
    "    \"lower_eye_x\", \"lower_eye_y\", \"upper_ear_x\", \"upper_ear_y\", \"lower_ear_x\",\n",
    "    \"lower_ear_y\", \"outer_ear_x\", \"outer_ear_y\", \"upper_whisker_x\",\n",
    "    \"upper_whisker_y\", \"outer_whisker_x\", \"outer_whisker_y\", \"lower_whisker_x\",\n",
    "    \"lower_whisker_y\", \"upper_mouth_x\", \"upper_mouth_y\", \"outer_mouth_x\",\n",
    "    \"outer_mouth_y\", \"lower_mouth_x\", \"lower_mouth_y\", \"inner_nostril_x\",\n",
    "    \"inner_nostril_y\", \"outer_nostril_x\", \"outer_nostril_y\"\n",
    "]\n",
    "\n",
    "for m, mouse in enumerate(mice):\n",
    "    n_weeks = len(exprs[m][\"timestamps\"])\n",
    "\n",
    "    # create variable arrays with the length of weeks\n",
    "    week_filter = np.zeros(n_weeks, dtype=bool)\n",
    "\n",
    "    # create variable arrays with the length of weeks\n",
    "    # create a list to store data from each week\n",
    "    dataframe = [{} for _ in range(n_weeks)]\n",
    "    data = [_ for _ in range(n_weeks)]\n",
    "\n",
    "    # iterate weeks\n",
    "    for w in range(n_weeks):\n",
    "\n",
    "        # for each week, convert the \"mouse\" variables (for each frame) into a numpy array\n",
    "        # Begin the dataframe\n",
    "        dataframe[w][columns[0]] = np.array(exprs[m][\"mouse_list\"][w],\n",
    "                                            dtype=str)\n",
    "\n",
    "        # Convert the frame # and week # into numpy arrays\n",
    "        for v in columns[1:3]:\n",
    "            dataframe[w][v] = np.array(exprs[m][v][w], dtype=np.int64)\n",
    "\n",
    "        # mean center the track points\n",
    "        for v in columns[3:29]:\n",
    "            if type(exprs[m][v][w]) == type(np.array([0, 1, 2, 3])):\n",
    "\n",
    "                means = np.mean(exprs[m][v][w], axis=0)\n",
    "\n",
    "                dataframe[w][v] = exprs[m][v][w] - means\n",
    "\n",
    "                week_filter[w] = True\n",
    "\n",
    "            else:\n",
    "                print(\n",
    "                    f\"\\terror mean centering mouse: {mouse}, dataset: {v}, week: {w}\"\n",
    "                )\n",
    "        for v in columns[0:3]:\n",
    "            dataframe[w][v] = dataframe[w][v][0:dataframe[w][columns[6]].\n",
    "                                                shape[0]]\n",
    "\n",
    "        # Concatenate all numpy arrays into 'week' pandas dataframe\n",
    "        data[w] = pd.DataFrame(dataframe[w], columns=columns)\n",
    "\n",
    "        print(\"\\tWeek:\", w, \"Num columns:\", len(dataframe[w].keys()),\n",
    "                \"-- done\") if week_filter[w] else print(\n",
    "                f\"\\t\\tDoes the data exist for mouse {mouse} on week {w}?\")\n",
    "\n",
    "    data = [d for i, d in enumerate(data) if week_filter[i]]\n",
    "\n",
    "    data = pd.concat(data, keys=[w for w in range(len(data))])\n",
    "    exprs[m]['data_by_mouse'] = data.dropna(how=\"any\", subset=[\"upper_eye_x\", \"upper_eye_y\", \"lower_eye_x\", \"lower_eye_y\", \"upper_ear_x\", \"upper_ear_y\", \"lower_ear_x\", \"lower_ear_y\", \"outer_ear_x\", \"outer_ear_y\", \"upper_whisker_x\", \"upper_whisker_y\", \"outer_whisker_x\", \"outer_whisker_y\", \"lower_whisker_x\", \"lower_whisker_y\", \"upper_mouth_x\", \"upper_mouth_y\", \"outer_mouth_x\", \"outer_mouth_y\", \"lower_mouth_x\", \"lower_mouth_y\", \"inner_nostril_x\", \"inner_nostril_y\", \"outer_nostril_x\", \"outer_nostril_y\"])\n",
    "    del (data)\n",
    "    del (dataframe)\n",
    "\n",
    "    print(mouse, \"-- complete\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSC009 -- starting\n",
      "CSC009 -- complete\n",
      "CSC013 -- starting\n",
      "CSC013 -- complete\n",
      "CSE008 -- starting\n",
      "CSE008 -- complete\n",
      "CSE021 -- starting\n",
      "CSE021 -- complete\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# enumerate mice\n",
    "for m, mouse in enumerate(mice):\n",
    "    print(mouse, \"-- starting\")\n",
    "        \n",
    "    # if the video exists and is processed\n",
    "    if type(exprs[m][\"data_by_mouse\"]) == type(pd.DataFrame()):\n",
    "\n",
    "        raw_data = exprs[m][\"data_by_mouse\"].loc[:, \"upper_eye_x\":\"outer_nostril_y\"]\n",
    "        targets = exprs[m][\"data_by_mouse\"].loc[:, \"mouse_list\":\"frame_list\"]\n",
    "\n",
    "        centered_data = raw_data.subtract(raw_data.mean())\n",
    "\n",
    "        centered_data = pd.concat([targets, centered_data], axis = 1)\n",
    "\n",
    "    exprs[m][\"data_by_mouse_centered\"] = centered_data.dropna(how=\"any\", subset=[\"upper_eye_x\", \"upper_eye_y\", \"lower_eye_x\", \"lower_eye_y\", \"upper_ear_x\", \"upper_ear_y\", \"lower_ear_x\", \"lower_ear_y\", \"outer_ear_x\", \"outer_ear_y\", \"upper_whisker_x\", \"upper_whisker_y\", \"outer_whisker_x\", \"outer_whisker_y\", \"lower_whisker_x\", \"lower_whisker_y\", \"upper_mouth_x\", \"upper_mouth_y\", \"outer_mouth_x\", \"outer_mouth_y\", \"lower_mouth_x\", \"lower_mouth_y\", \"inner_nostril_x\", \"inner_nostril_y\", \"outer_nostril_x\", \"outer_nostril_y\"])\n",
    "\n",
    "    del(centered_data)\n",
    "    del(raw_data)\n",
    "    del(targets)\n",
    "\n",
    "    print(mouse, \"-- complete\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning...\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning...\")\n",
    "del(end)\n",
    "del(end_difference_array)\n",
    "del(end_index)\n",
    "del(i)\n",
    "del(led)\n",
    "del(led_end_array)\n",
    "del(led_start_array)\n",
    "del(m)\n",
    "del(mouse)\n",
    "del(n_weeks)\n",
    "del(speaker)\n",
    "del(start)\n",
    "del(start_difference_array)\n",
    "del(start_index)\n",
    "del(trial)\n",
    "del(trial_type)\n",
    "del(v)\n",
    "del(w)\n",
    "del(week_filter)\n",
    "del(weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSC009 -- starting\n",
      "CSC009 -- complete\n",
      "CSC013 -- starting\n",
      "CSC013 -- complete\n",
      "CSE008 -- starting\n",
      "CSE008 -- complete\n",
      "CSE021 -- starting\n",
      "CSE021 -- complete\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# enumerate mice\n",
    "for m, mouse in enumerate(mice):\n",
    "    print(mouse, \"-- starting\")\n",
    "        \n",
    "    # if the video exists and is processed\n",
    "    if type(exprs[m][\"trial_data_by_mouse\"]) == type(pd.DataFrame()):\n",
    "\n",
    "        raw_data = exprs[m][\"trial_data_by_mouse\"].loc[:, \"upper_eye_x\":\"outer_nostril_y\"]\n",
    "        targets = exprs[m][\"trial_data_by_mouse\"].loc[:, \"mouse_list\":\"trial_type\"]\n",
    "\n",
    "        trial_data_centered = raw_data.subtract(raw_data.mean())\n",
    "\n",
    "        trial_data_centered= pd.concat([targets, trial_data_centered], axis = 1)\n",
    "\n",
    "    exprs[m][\"trial_data_by_mouse_centered\"] = trial_data_centered.dropna(thresh=4, subset=[\"upper_eye_x\", \"upper_eye_y\", \"lower_eye_x\", \"lower_eye_y\", \"upper_ear_x\", \"upper_ear_y\", \"lower_ear_x\", \"lower_ear_y\", \"outer_ear_x\", \"outer_ear_y\", \"upper_whisker_x\", \"upper_whisker_y\", \"outer_whisker_x\", \"outer_whisker_y\", \"lower_whisker_x\", \"lower_whisker_y\", \"upper_mouth_x\", \"upper_mouth_y\", \"outer_mouth_x\", \"outer_mouth_y\", \"lower_mouth_x\", \"lower_mouth_y\", \"inner_nostril_x\", \"inner_nostril_y\", \"outer_nostril_x\", \"outer_nostril_y\"])\n",
    "\n",
    "    del(trial_data_centered)\n",
    "    del(raw_data)\n",
    "    del(targets)\n",
    "\n",
    "    print(mouse, \"-- complete\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_data = [ _ for _ in range(len(mice))]\n",
    "centered_dataframes_data = [ _ for _ in range(len(mice))]\n",
    "dataframes_trials = [ _ for _ in range(len(mice))]\n",
    "centered_dataframes_trials = [ _ for _ in range(len(mice))]\n",
    "trial_type = [\n",
    "            \"Airpuff\", \"Sucrose\", \"Airpuff catch\", \"Sucrose catch\",\n",
    "            \"Airpuff with LED\", \"Sucrose with LED\", \"LED only\"\n",
    "        ]\n",
    "trial_type_name = [\n",
    "            \"Airpuff\", \"Sucrose\", \"Airpuff_catch\", \"Sucrose_catch\",\n",
    "            \"Airpuff_with_LED\", \"Sucrose_with_LED\", \"LED_only\"\n",
    "        ]\n",
    "\n",
    "all_data_and_pcas = {}\n",
    "\n",
    "for m in range(len(mice)):\n",
    "\n",
    "    dataframes_data[m] = exprs[m][\"data_by_mouse\"]\n",
    "    centered_dataframes_data[m] = exprs[m][\"data_by_mouse_centered\"]\n",
    "\n",
    "    targets_list = exprs[m][\"data_by_mouse\"].loc[:, \"mouse_list\":\"frame_list\"]\n",
    "    centered_targets_list = exprs[m][\"data_by_mouse_centered\"].loc[:, \"mouse_list\":\"frame_list\"]\n",
    "\n",
    "    data_frame = exprs[m][\"data_by_mouse\"].loc[:, \"upper_eye_x\":\"outer_nostril_y\"]\n",
    "    centered_data_frame = exprs[m][\"data_by_mouse_centered\"].loc[:, \"upper_eye_x\":\"outer_nostril_y\"]\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    data_frame_pca = pca.fit_transform(data_frame)\n",
    "    centered_data_frame_pca = pca.fit_transform(centered_data_frame)\n",
    "\n",
    "    principalDf = pd.DataFrame(\n",
    "        data_frame_pca, columns=[\"principal component 1\", \"principal component 2\"]\n",
    "    )\n",
    "    centered_principalDf = pd.DataFrame(\n",
    "        centered_data_frame_pca, columns=[\"principal component 1\", \"principal component 2\"]\n",
    "    )\n",
    "\n",
    "    exprs[m][\"D2_PCA_by_mouse\"] = pd.concat([targets_list.reset_index(), principalDf], axis=1)\n",
    "    exprs[m][\"D2_PCA_by_mouse_centered\"] = pd.concat([centered_targets_list.reset_index(), centered_principalDf], axis=1)\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "\n",
    "    data_frame_pca = pca.fit_transform(data_frame)\n",
    "    centered_data_frame_pca = pca.fit_transform(centered_data_frame)\n",
    "\n",
    "    principalDf = pd.DataFrame(\n",
    "        data_frame_pca, columns=[\"principal component 1\", \"principal component 2\", \"principal component 3\"]\n",
    "    )\n",
    "    centered_principalDf = pd.DataFrame(\n",
    "        centered_data_frame_pca, columns=[\"principal component 1\", \"principal component 2\", \"principal component 3\"]\n",
    "    )\n",
    "\n",
    "    exprs[m][\"D3_PCA_by_mouse\"] = pd.concat([targets_list.reset_index(), principalDf], axis=1)\n",
    "    exprs[m][\"D3_PCA_by_mouse_centered\"] = pd.concat([centered_targets_list.reset_index(), centered_principalDf], axis=1)\n",
    "\n",
    "    dataframes_trials[m] = exprs[m][\"trial_data_by_mouse\"]\n",
    "    centered_dataframes_trials[m] = exprs[m][\"trial_data_by_mouse_centered\"]\n",
    "\n",
    "    targets_list = exprs[m][\"trial_data_by_mouse\"].loc[:, \"mouse_list\":\"trial_type\"]\n",
    "    centered_targets_list = exprs[m][\"trial_data_by_mouse_centered\"].loc[:, \"mouse_list\":\"trial_type\"]\n",
    "    \n",
    "    data_frame = exprs[m][\"trial_data_by_mouse\"].loc[:, \"upper_eye_x\":\"outer_nostril_y\"]\n",
    "    centered_data_frame = exprs[m][\"trial_data_by_mouse_centered\"].loc[:, \"upper_eye_x\":\"outer_nostril_y\"]\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "    data_frame_pca = pca.fit_transform(data_frame)\n",
    "    centered_data_frame_pca = pca.fit_transform(centered_data_frame)\n",
    "\n",
    "    principalDf = pd.DataFrame(\n",
    "        data_frame_pca, columns=[\"principal component 1\", \"principal component 2\", \"principal component 3\"]\n",
    "    )\n",
    "    centered_principalDf = pd.DataFrame(\n",
    "        centered_data_frame_pca, columns=[\"principal component 1\", \"principal component 2\", \"principal component 3\"]\n",
    "    )\n",
    "\n",
    "    finalDf = pd.concat([targets_list.reset_index(), principalDf], axis=1)\n",
    "    centered_finalDf = pd.concat([centered_targets_list.reset_index(), centered_principalDf], axis=1)\n",
    "\n",
    "    finalDf.loc[:, [\"mouse_list\", \"week_list\"]] = finalDf.astype({'mouse_list': str, 'week_list': str})\n",
    "    centered_finalDf.loc[:, [\"mouse_list\", \"week_list\"]] = centered_finalDf.astype({'mouse_list': str, 'week_list': str})\n",
    "\n",
    "    exprs[m][\"D3_PCA_raw_trial_data_by_mouse\"] = finalDf\n",
    "    exprs[m][\"D3_PCA_trial_data_centered_by_mouse\"] = centered_finalDf\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    data_frame_pca = pca.fit_transform(data_frame)\n",
    "    centered_data_frame_pca = pca.fit_transform(centered_data_frame)\n",
    "\n",
    "    principalDf = pd.DataFrame(\n",
    "        data_frame_pca, columns=[\"principal component 1\", \"principal component 2\"]\n",
    "    )\n",
    "    centered_principalDf = pd.DataFrame(\n",
    "        centered_data_frame_pca, columns=[\"principal component 1\", \"principal component 2\"]\n",
    "    )\n",
    "\n",
    "    exprs[m][\"D2_PCA_raw_trial_data_by_mouse\"] = pd.concat([targets_list.reset_index(), principalDf], axis=1)\n",
    "    exprs[m][\"D2_PCA_trial_data_centered_by_mouse\"] = pd.concat([centered_targets_list.reset_index(), centered_principalDf], axis=1)\n",
    "\n",
    "all_data_and_pcas[\"all_data\"] = pd.concat(dataframes_data, keys=mice)\n",
    "all_data_and_pcas[\"all_data_centered\"] = pd.concat(centered_dataframes_data, keys=mice)\n",
    "all_data_and_pcas[\"all_trial_data\"] = pd.concat(dataframes_trials, keys=mice)\n",
    "all_data_and_pcas[\"all_trial_data_centered\"] = pd.concat(centered_dataframes_trials, keys=mice)\n",
    "\n",
    "data = all_data_and_pcas[\"all_trial_data\"]\n",
    "centered_data = all_data_and_pcas[\"all_trial_data_centered\"]\n",
    "\n",
    "non_numeric_cols = data.loc[:, \"mouse_list\":\"trial_type\"]\n",
    "non_numeric_cols_centered = centered_data.loc[:, \"mouse_list\":\"trial_type\"]\n",
    "\n",
    "numeric_cols = data.loc[:, \"upper_eye_x\":\"outer_nostril_y\"]\n",
    "centered_numeric_cols = centered_data.loc[:, \"upper_eye_x\":\"outer_nostril_y\"]\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "data_frame_pca = pca.fit_transform(numeric_cols)\n",
    "data_frame_pca_centered = pca.fit_transform(centered_numeric_cols)\n",
    "\n",
    "principalDf = pd.DataFrame(\n",
    "        data_frame_pca, columns=[\"principal component 1\", \"principal component 2\"]\n",
    "    )\n",
    "principalDf_centered = pd.DataFrame(\n",
    "        data_frame_pca_centered, columns=[\"principal component 1\", \"principal component 2\"]\n",
    "    )\n",
    "\n",
    "all_data_and_pcas[\"D2_PCA_trial_data\"] = pd.concat([non_numeric_cols.reset_index(), principalDf], axis=1)\n",
    "all_data_and_pcas[\"D2_PCA_trial_data_centered\"] = pd.concat([non_numeric_cols_centered.reset_index(), principalDf_centered], axis=1)\n",
    "\n",
    "std_x = statistics.stdev(principalDf.std(0).to_list())\n",
    "std_y = statistics.stdev(principalDf.std(1).to_list())\n",
    "cen_std_x = statistics.stdev(principalDf_centered.std(0).to_list())\n",
    "cen_std_y = statistics.stdev(principalDf_centered.std(1).to_list())\n",
    "\n",
    "principalDf_blurred = cv2.GaussianBlur(principalDf.to_numpy(), (3,3), sigmaX=std_x, sigmaY=std_y)\n",
    "principalDf_blurred = pd.DataFrame(\n",
    "        principalDf_blurred, columns=[\"principal component 1\", \"principal component 2\",]\n",
    "    )\n",
    "\n",
    "principalDf_centered_blurred = cv2.GaussianBlur(principalDf_centered.to_numpy(), (3,3), sigmaX=cen_std_x, sigmaY=cen_std_y)\n",
    "principalDf_centered_blurred = pd.DataFrame(\n",
    "        principalDf_centered_blurred, columns=[\"principal component 1\", \"principal component 2\"]\n",
    "    )\n",
    "\n",
    "all_data_and_pcas[\"D2_PCA_trial_data_blurred\"] = pd.concat([non_numeric_cols.reset_index(), principalDf_blurred], axis=1)\n",
    "all_data_and_pcas[\"D2_PCA_trial_data_centered_blurred\"] = pd.concat([non_numeric_cols_centered.reset_index(), principalDf_centered_blurred], axis=1)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "data_frame_pca = pca.fit_transform(numeric_cols)\n",
    "data_frame_pca_centered = pca.fit_transform(centered_numeric_cols)\n",
    "\n",
    "principalDf = pd.DataFrame(\n",
    "        data_frame_pca, columns=[\"principal component 1\", \"principal component 2\", \"principal component 3\"]\n",
    "    )\n",
    "principalDf_centered = pd.DataFrame(\n",
    "        data_frame_pca_centered, columns=[\"principal component 1\", \"principal component 2\", \"principal component 3\"]\n",
    "    )\n",
    "\n",
    "all_data_and_pcas[\"D3_PCA_trial_data\"] = pd.concat([non_numeric_cols.reset_index(), principalDf], axis=1)\n",
    "all_data_and_pcas[\"D3_PCA_trial_data_centered\"] = pd.concat([non_numeric_cols_centered.reset_index(), principalDf_centered], axis=1)\n",
    "\n",
    "std_x = statistics.stdev(principalDf.std(0).to_list())\n",
    "std_y = statistics.stdev(principalDf.std(1).to_list())\n",
    "cen_std_x = statistics.stdev(principalDf_centered.std(0).to_list())\n",
    "cen_std_y = statistics.stdev(principalDf_centered.std(1).to_list())\n",
    "\n",
    "principalDf_blurred = cv2.GaussianBlur(principalDf.to_numpy(), (3,3), sigmaX=std_x, sigmaY=std_y)\n",
    "principalDf_blurred = pd.DataFrame(\n",
    "        principalDf_blurred, columns=[\"principal component 1\", \"principal component 2\", \"principal component 3\"]\n",
    "    )\n",
    "\n",
    "principalDf_centered_blurred = cv2.GaussianBlur(principalDf_centered.to_numpy(), (3,3), sigmaX=cen_std_x, sigmaY=cen_std_y)\n",
    "principalDf_centered_blurred = pd.DataFrame(\n",
    "        principalDf_centered_blurred, columns=[\"principal component 1\", \"principal component 2\", \"principal component 3\"]\n",
    "    )\n",
    "\n",
    "all_data_and_pcas[\"D2_PCA_trial_data_blurred\"] = pd.concat([non_numeric_cols.reset_index(), principalDf_blurred], axis=1)\n",
    "all_data_and_pcas[\"D2_PCA_trial_data_centered_blurred\"] = pd.concat([non_numeric_cols_centered.reset_index(), principalDf_centered_blurred], axis=1)\n",
    "\n",
    "for i in range(len(trial_type)):\n",
    "    if not data[data.trial_type.isin([trial_type[i]])].empty:\n",
    "        data =  data[data.trial_type == trial_type[i]]\n",
    "        centered_data =  centered_data[centered_data.trial_type == trial_type[i]]\n",
    "\n",
    "        non_numeric_cols = data.loc[:, \"mouse_list\":\"trial_type\"]\n",
    "        non_numeric_cols_centered = centered_data.loc[:, \"mouse_list\":\"trial_type\"]\n",
    "\n",
    "        numeric_cols = data.loc[:, \"upper_eye_x\":\"outer_nostril_y\"]\n",
    "        centered_numeric_cols = centered_data.loc[:, \"upper_eye_x\":\"outer_nostril_y\"]\n",
    "\n",
    "        pca = PCA(n_components=2)\n",
    "\n",
    "        data_frame_pca = pca.fit_transform(numeric_cols)\n",
    "        data_frame_pca_centered = pca.fit_transform(centered_numeric_cols)\n",
    "\n",
    "        principalDf = pd.DataFrame(\n",
    "                data_frame_pca, columns=[\"principal component 1\", \"principal component 2\"]\n",
    "            )\n",
    "        principalDf_centered = pd.DataFrame(\n",
    "                data_frame_pca_centered, columns=[\"principal component 1\", \"principal component 2\"]\n",
    "            )\n",
    "\n",
    "        all_data_and_pcas[f\"D2_PCA_{trial_type_name[i]}\"] = pd.concat([non_numeric_cols.reset_index(), principalDf], axis=1)\n",
    "        all_data_and_pcas[f\"D2_PCA_{trial_type_name[i]}_centered\"] = pd.concat([non_numeric_cols_centered.reset_index(), principalDf_centered], axis=1)\n",
    "\n",
    "        std_x = statistics.stdev(principalDf.std(0).to_list())\n",
    "        std_y = statistics.stdev(principalDf.std(1).to_list())\n",
    "        cen_std_x = statistics.stdev(principalDf_centered.std(0).to_list())\n",
    "        cen_std_y = statistics.stdev(principalDf_centered.std(1).to_list())\n",
    "\n",
    "        principalDf_blurred = cv2.GaussianBlur(principalDf.to_numpy(), (3,3), sigmaX=std_x, sigmaY=std_y)\n",
    "        principalDf_blurred = pd.DataFrame(\n",
    "                principalDf_blurred, columns=[\"principal component 1\", \"principal component 2\",]\n",
    "            )\n",
    "\n",
    "        principalDf_centered_blurred = cv2.GaussianBlur(principalDf_centered.to_numpy(), (3,3), sigmaX=cen_std_x, sigmaY=cen_std_y)\n",
    "        principalDf_centered_blurred = pd.DataFrame(\n",
    "                principalDf_centered_blurred, columns=[\"principal component 1\", \"principal component 2\"]\n",
    "            )\n",
    "\n",
    "        all_data_and_pcas[f\"D2_PCA_{trial_type_name[i]}_blurred\"] = pd.concat([non_numeric_cols.reset_index(), principalDf_blurred], axis=1)\n",
    "        all_data_and_pcas[f\"D2_PCA_{trial_type_name[i]}_centered_blurred\"] = pd.concat([non_numeric_cols_centered.reset_index(), principalDf_centered_blurred], axis=1)\n",
    "\n",
    "        pca = PCA(n_components=3)\n",
    "\n",
    "        data_frame_pca = pca.fit_transform(numeric_cols)\n",
    "        data_frame_pca_centered = pca.fit_transform(centered_numeric_cols)\n",
    "\n",
    "        principalDf = pd.DataFrame(\n",
    "                data_frame_pca, columns=[\"principal component 1\", \"principal component 2\", \"principal component 3\"]\n",
    "            )\n",
    "        principalDf_centered = pd.DataFrame(\n",
    "                data_frame_pca_centered, columns=[\"principal component 1\", \"principal component 2\", \"principal component 3\"]\n",
    "            )\n",
    "\n",
    "        all_data_and_pcas[f\"D3_PCA_{trial_type_name[i]}\"] = pd.concat([non_numeric_cols.reset_index(), principalDf], axis=1)\n",
    "        all_data_and_pcas[f\"D3_PCA_{trial_type_name[i]}_centered\"] = pd.concat([non_numeric_cols_centered.reset_index(), principalDf_centered], axis=1)\n",
    "\n",
    "        std_x = statistics.stdev(principalDf.std(0).to_list())\n",
    "        std_y = statistics.stdev(principalDf.std(1).to_list())\n",
    "        cen_std_x = statistics.stdev(principalDf_centered.std(0).to_list())\n",
    "        cen_std_y = statistics.stdev(principalDf_centered.std(1).to_list())\n",
    "\n",
    "        principalDf_blurred = cv2.GaussianBlur(principalDf.to_numpy(), (3,3), sigmaX=std_x, sigmaY=std_y)\n",
    "        principalDf_blurred = pd.DataFrame(\n",
    "                principalDf_blurred, columns=[\"principal component 1\", \"principal component 2\", \"principal component 3\"]\n",
    "            )\n",
    "\n",
    "        principalDf_centered_blurred = cv2.GaussianBlur(principalDf_centered.to_numpy(), (3,3), sigmaX=cen_std_x, sigmaY=cen_std_y)\n",
    "        principalDf_centered_blurred = pd.DataFrame(\n",
    "                principalDf_centered_blurred, columns=[\"principal component 1\", \"principal component 2\", \"principal component 3\"]\n",
    "            )\n",
    "\n",
    "        all_data_and_pcas[f\"D3_PCA_{trial_type_name[i]}_blurred\"] = pd.concat([non_numeric_cols.reset_index(), principalDf_blurred], axis=1)\n",
    "        all_data_and_pcas[f\"D3_PCA_{trial_type_name[i]}_centered_blurred\"] = pd.concat([non_numeric_cols_centered.reset_index(), principalDf_centered_blurred], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSC009 -- saving metadata\n",
      "CSC013 -- saving metadata\n",
      "CSE008 -- saving metadata\n",
      "CSE021 -- saving metadata\n",
      "CSC009 -- saving datatables\n",
      "CSC013 -- saving datatables\n",
      "CSE008 -- saving datatables\n",
      "CSE021 -- saving datatables\n",
      "Saving concatenated data\n"
     ]
    }
   ],
   "source": [
    "# export data\n",
    "hf = h5py.File(\"/Users/annieehler/Projects/Jupyter_Notebooks/python_outputs/metadata.h5\", \"w\")\n",
    "\n",
    "for m, mouse in enumerate(mice):\n",
    "    print(f\"{mouse} -- saving metadata\")\n",
    "    \n",
    "    for key in list(exprs[m].keys()):\n",
    "        if type(exprs[m][key]) is list or type(exprs[m][key]) is np.array:\n",
    "            for w in range(len(exprs[m][key])):\n",
    "                \n",
    "                if type(exprs[m][key][w]) is list or type(exprs[m][key][w]) is np.array:\n",
    "                    hf.create_dataset(f\"{mouse}/{w}/{key}\", data=exprs[m][key][w])\n",
    "\n",
    "                if type(exprs[m][key][w]) is dict:\n",
    "                    g = hf.create_group(f\"{mouse}/{w}/{key}\")\n",
    "                    hdfdict.dump(data=exprs[m][key][w], hdf=g)\n",
    "\n",
    "hf.close()\n",
    "\n",
    "hf = pd.HDFStore(\"/Users/annieehler/Projects/Jupyter_Notebooks/python_outputs/datatables.h5\", \"a\")\n",
    "for m, mouse in enumerate(mice):\n",
    "    print(f\"{mouse} -- saving datatables\")\n",
    "    \n",
    "    for key in list(exprs[m].keys()):\n",
    "        if type(exprs[m][key]) is pd.DataFrame:\n",
    "            hf.put(f\"{mouse}/{key}\", exprs[m][key])\n",
    "            \n",
    "hf.close()\n",
    "hf = pd.HDFStore(\"/Users/annieehler/Projects/Jupyter_Notebooks/python_outputs/data.h5\", \"a\")\n",
    "\n",
    "print(f\"Saving concatenated data\")\n",
    "for key in list(all_data_and_pcas.keys()):\n",
    "    hf.put(f\"{key}\", all_data_and_pcas[key])\n",
    "\n",
    "hf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('facial_expr_analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c46671d8a28cd4c39bdbaa334ef9fc13d45eb5be1200cb4073f1b1f6c0ca705"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
